{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "from sklearn.externals import joblib\n",
    "from collections import Counter\n",
    "from scipy import signal\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = joblib.load('data.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['features', 'labels', 'bounds', 'lens', 'label_encoder'])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def standard_scale(data):\n",
    "#     features = data['features']\n",
    "#     lens = np.concatenate((data['lens']['train'],data['lens']['valid'],data['lens']['test']))\n",
    "#     features = np.concatenate(features, axis=0)\n",
    "#     features = StandardScaler().fit_transform(features)\n",
    "#     ret = []\n",
    "#     l = 0\n",
    "#     for t in lens:\n",
    "#         ret.append(features[l: l + t])\n",
    "#         l += t\n",
    "#     features = np.array(ret)\n",
    "#     data['features'] = features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_emg(x):\n",
    "    high = 20/(1000/2)\n",
    "    low = 450/(1000/2)\n",
    "    b, a = signal.butter(4, [high, low], btype='bandpass')\n",
    "    emg_filtered = signal.filtfilt(b, a, x, axis=0)\n",
    "    return emg_filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# standard_scale(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_split(data, split):\n",
    "    if split == 'train':\n",
    "        return data['features'][: data['bounds']['train']]\n",
    "    elif split == 'valid':\n",
    "        return data['features'][data['bounds']['train']: data['bounds']['train'] + data['bounds']['valid']]\n",
    "    elif split == 'test':\n",
    "        return data['features'][data['bounds']['train'] + data['bounds']['valid']:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_batch_idx(n, batch_size, randomise=False):\n",
    "    idx = np.arange(0, n)\n",
    "    if randomise:\n",
    "        np.random.shuffle(idx)\n",
    "    for batch_idx in np.arange(0, n, batch_size):\n",
    "        yield idx[batch_idx:batch_idx+batch_size]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_batches(data, split, batch_size,\n",
    "                     time_steps=10, stride=5, randomise=False):\n",
    "    features = get_split(data, split)\n",
    "\n",
    "    try:\n",
    "        labels = data['label_encoder'].transform(data['labels'][split])\n",
    "    except:\n",
    "        labels = np.zeros(features.shape[0])\n",
    "    \n",
    "    lens = data['lens'][split]\n",
    "    new_features = []\n",
    "    new_labels = []\n",
    "    new_lens = []\n",
    "    for i in range(len(lens)):\n",
    "        mat = features[i]\n",
    "        label = labels[i]\n",
    "        l = lens[i]\n",
    "        acc_emg = [0, 1, 2, 3, 5, 6, 7, 9, 10, 11]\n",
    "        mat[:, acc_emg] -= mat[:, acc_emg].mean(axis=0)\n",
    "        mat[:, :4] = filter_emg(mat[:, :4])\n",
    "        extracted_steps = []\n",
    "        for j in range(0, len(mat) - time_steps, stride):\n",
    "            window = mat[j: j + time_steps, :]\n",
    "            means = window[:, 4:].mean(axis=0).reshape(1, -1)\n",
    "            rms = np.sqrt((window[:, :4]**2).mean(axis=0)).reshape(1, -1)\n",
    "            feature_vector = np.concatenate((rms, means), axis=1).reshape(1, -1)\n",
    "            \n",
    "            extracted_steps.append(feature_vector)\n",
    "        extracted_steps = np.concatenate(extracted_steps, axis=0)\n",
    "        new_features.append(extracted_steps)\n",
    "        new_labels.append(label)\n",
    "        new_lens.append(len(extracted_steps))\n",
    "    features = np.array(new_features)\n",
    "    labels = np.array(new_labels)\n",
    "    lens = np.array(new_lens)\n",
    "    \n",
    "    n = len(features)\n",
    "    for batch_idx in generate_batch_idx(n, batch_size, randomise):\n",
    "        batch_data = features[batch_idx]\n",
    "        batch_labels = labels[batch_idx]\n",
    "        batch_lens = lens[batch_idx]\n",
    "#         batch_data = torch.from_numpy(batch_data).float()\n",
    "#         batch_labels = torch.from_numpy(labels[batch_idx]).float()\n",
    "#         lens = torch.from_numpy(lens[batch_idx]).float()\n",
    "        yield batch_data, batch_labels, batch_lens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def sort_batch(batch, targets, lengths):\n",
    "#     \"\"\"\n",
    "#     Sort a minibatch by the length of the sequences with the longest sequences first\n",
    "#     return the sorted batch targes and sequence lengths.\n",
    "#     This way the output can be used by pack_padded_sequences(...)\n",
    "#     \"\"\"\n",
    "#     perm_idx = np.argsort(lengths)[::-1]\n",
    "#     seq_lengths = lengths[perm_idx]\n",
    "#     seq_tensor = batch[perm_idx]\n",
    "#     target_tensor = targets[perm_idx]\n",
    "#     return seq_tensor, target_tensor, seq_lengths\n",
    "\n",
    "def pad_batch(batch, lens):\n",
    "    max_len = max(lens)\n",
    "    batch_size = batch.shape[0]\n",
    "    num_feature = batch[0].shape[1]\n",
    "    padded_seqs = np.zeros((batch_size, max_len, num_feature))\n",
    "    \n",
    "    for i, l in enumerate(lens):\n",
    "        padded_seqs[i, :l, :] = batch[i][:l]\n",
    "\n",
    "    return padded_seqs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def torch_batch(batch, targets):\n",
    "    return torch.from_numpy(batch).float(), torch.from_numpy(targets).long()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_preds(model, data, split, batch_size, time_steps, stride):\n",
    "    model.eval()\n",
    "    preds = []\n",
    "    labels = []\n",
    "    with torch.no_grad():\n",
    "        for b_data, b_labels, b_lens in generate_batches(data, split, batch_size, \n",
    "                                                         time_steps, stride, False):\n",
    "            b_data = pad_batch(b_data, b_lens)\n",
    "            b_data, b_labels = torch_batch(b_data, b_labels)\n",
    "            preds.append(model(b_data, b_lens))\n",
    "            labels.append(b_labels)\n",
    "        preds = torch.cat(preds, dim=0)\n",
    "        labels = torch.cat(labels, dim=0)\n",
    "    return preds, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_accuracy(preds, labels, le):\n",
    "    preds = preds.max(dim=1)[1].numpy()\n",
    "    preds = [le.classes_[i] for i in preds]\n",
    "    labels = labels.numpy()\n",
    "    labels = [le.classes_[i] for i in labels]\n",
    "    return accuracy_score(labels, preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HARNet(nn.Module):\n",
    "    def __init__(self, ):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv1d(19, 64, 8)\n",
    "        self.conv2 = nn.Conv1d(64, 128, 8)\n",
    "        self.maxpool1 = nn.MaxPool1d(4)\n",
    "        self.conv3 = nn.Conv1d(128, 64, 8)\n",
    "        self.conv4 = nn.Conv1d(64, 64, 4)\n",
    "#         self.avgpool1 = nn.AvgPool1d(4)\n",
    "        self.dropout = nn.Dropout(.2)\n",
    "        self.lin1 = nn.Linear(64*3,22)\n",
    "        \n",
    "    def forward(self, data, lens):\n",
    "        data = data.transpose(1,2)\n",
    "        x = self.conv1(data)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.maxpool1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv3(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv4(x)\n",
    "        x = torch.cat((x.mean(dim=2), x.min(dim=2)[0], x.max(dim=2)[0]), dim=1)\n",
    "        x = self.dropout(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.lin1(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch: 1] | Batch 180 | Loss: 15.052666171391804: : 180it [00:38, 13.83it/s]\n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss improved from inf to 2.8088064193725586\n",
      "Validation accuracy: 0.1189358372456964\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch: 2] | Batch 180 | Loss: 8.83424322406451: : 180it [00:38,  4.68it/s]  \n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss improved from 2.8088064193725586 to 2.335017204284668\n",
      "Validation accuracy: 0.18466353677621283\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch: 3] | Batch 180 | Loss: 6.670256291495429: : 180it [00:42,  4.20it/s] \n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss improved from 2.335017204284668 to 2.2054688930511475\n",
      "Validation accuracy: 0.2112676056338028\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch: 4] | Batch 180 | Loss: 5.560101707610819: : 180it [00:39,  4.54it/s] \n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss improved from 2.2054688930511475 to 2.078712224960327\n",
      "Validation accuracy: 0.25508607198748046\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch: 5] | Batch 180 | Loss: 4.882208083205753: : 180it [00:38,  4.71it/s] \n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss improved from 2.078712224960327 to 2.0682897567749023\n",
      "Validation accuracy: 0.28482003129890454\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch: 6] | Batch 180 | Loss: 4.425819495872215: : 180it [00:46,  3.88it/s] \n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss improved from 2.0682897567749023 to 2.0609207153320312\n",
      "Validation accuracy: 0.25508607198748046\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch: 7] | Batch 180 | Loss: 4.0873875406053335: : 180it [00:47,  3.76it/s]\n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss improved from 2.0609207153320312 to 1.9338470697402954\n",
      "Validation accuracy: 0.3348982785602504\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch: 8] | Batch 180 | Loss: 3.8246031049225064: : 180it [00:48,  3.74it/s]\n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss improved from 1.9338470697402954 to 1.86893892288208\n",
      "Validation accuracy: 0.3380281690140845\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch: 9] | Batch 180 | Loss: 3.6220894274152355: : 180it [00:58,  5.06it/s]\n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss improved from 1.86893892288208 to 1.786018967628479\n",
      "Validation accuracy: 0.37402190923317685\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch: 10] | Batch 180 | Loss: 3.4521975760327446: : 180it [01:22,  4.38it/s]\n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss improved from 1.786018967628479 to 1.7749454975128174\n",
      "Validation accuracy: 0.36306729264475746\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch: 11] | Batch 180 | Loss: 3.306398932139079: : 180it [01:19,  4.40it/s] \n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss improved from 1.7749454975128174 to 1.7451066970825195\n",
      "Validation accuracy: 0.41471048513302033\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch: 12] | Batch 180 | Loss: 3.176460279138: : 180it [01:19,  4.28it/s]    \n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss improved from 1.7451066970825195 to 1.6876899003982544\n",
      "Validation accuracy: 0.41471048513302033\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch: 13] | Batch 180 | Loss: 3.0636081647159705: : 180it [01:13,  4.54it/s]\n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss improved from 1.6876899003982544 to 1.5839236974716187\n",
      "Validation accuracy: 0.4522691705790297\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch: 14] | Batch 180 | Loss: 2.965014170465015: : 180it [01:14,  4.81it/s] \n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss improved from 1.5839236974716187 to 1.5485446453094482\n",
      "Validation accuracy: 0.4522691705790297\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch: 15] | Batch 180 | Loss: 2.8765870292981464: : 180it [01:13,  4.72it/s]\n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss improved from 1.5485446453094482 to 1.468976616859436\n",
      "Validation accuracy: 0.49295774647887325\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch: 16] | Batch 180 | Loss: 2.793602237270938: : 180it [01:11,  4.66it/s] \n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss did not improve\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch: 17] | Batch 180 | Loss: 2.7215028848133835: : 180it [01:10,  4.84it/s]\n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss improved from 1.468976616859436 to 1.3766539096832275\n",
      "Validation accuracy: 0.4835680751173709\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch: 18] | Batch 180 | Loss: 2.6539720512466665: : 180it [01:10,  5.12it/s]\n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss improved from 1.3766539096832275 to 1.373326063156128\n",
      "Validation accuracy: 0.4945226917057903\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch: 19] | Batch 180 | Loss: 2.5918031407727136: : 180it [01:06,  5.27it/s]\n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss improved from 1.373326063156128 to 1.35984206199646\n",
      "Validation accuracy: 0.49921752738654146\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch: 20] | Batch 180 | Loss: 2.53811689219541: : 180it [01:05,  5.64it/s]  \n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss improved from 1.35984206199646 to 1.3202146291732788\n",
      "Validation accuracy: 0.5352112676056338\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch: 21] | Batch 180 | Loss: 2.484073953842991: : 180it [01:09,  5.33it/s] \n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss improved from 1.3202146291732788 to 1.2600979804992676\n",
      "Validation accuracy: 0.5492957746478874\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch: 22] | Batch 180 | Loss: 2.4349537151780996: : 180it [01:10,  4.94it/s]\n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss improved from 1.2600979804992676 to 1.238937497138977\n",
      "Validation accuracy: 0.5539906103286385\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch: 23] | Batch 180 | Loss: 2.3877262581373757: : 180it [01:21,  3.87it/s]\n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss improved from 1.238937497138977 to 1.232243299484253\n",
      "Validation accuracy: 0.5805946791862285\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch: 24] | Batch 180 | Loss: 2.3426841274593717: : 180it [01:18,  4.36it/s]\n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss did not improve\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch: 25] | Batch 180 | Loss: 2.302709248476558: : 180it [01:14,  4.59it/s] \n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss improved from 1.232243299484253 to 1.2063792943954468\n",
      "Validation accuracy: 0.5665101721439749\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch: 26] | Batch 180 | Loss: 2.264157097130759: : 180it [01:14,  4.52it/s] \n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss improved from 1.2063792943954468 to 1.1855942010879517\n",
      "Validation accuracy: 0.5696400625978091\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch: 27] | Batch 180 | Loss: 2.2259029984228897: : 180it [01:12,  4.47it/s]\n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss improved from 1.1855942010879517 to 1.1633621454238892\n",
      "Validation accuracy: 0.5508607198748043\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch: 28] | Batch 180 | Loss: 2.191855466129288: : 180it [01:11,  4.55it/s] \n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss improved from 1.1633621454238892 to 1.159451961517334\n",
      "Validation accuracy: 0.5712050078247262\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch: 29] | Batch 180 | Loss: 2.1587350577230198: : 180it [01:14,  4.18it/s]\n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss did not improve\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch: 30] | Batch 180 | Loss: 2.12684331084843: : 180it [01:16,  4.26it/s]  \n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss improved from 1.159451961517334 to 1.085875153541565\n",
      "Validation accuracy: 0.594679186228482\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch: 31] | Batch 180 | Loss: 2.097572628208386: : 180it [01:17,  4.51it/s] \n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss improved from 1.085875153541565 to 1.0731785297393799\n",
      "Validation accuracy: 0.6165884194053208\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch: 32] | Batch 180 | Loss: 2.067651619638006: : 180it [01:02,  5.24it/s] \n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss did not improve\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch: 33] | Batch 180 | Loss: 2.0397774159406574: : 180it [01:03,  5.39it/s]\n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss did not improve\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch: 34] | Batch 180 | Loss: 2.013298524127287: : 180it [01:00,  5.53it/s] \n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss improved from 1.0731785297393799 to 1.0509331226348877\n",
      "Validation accuracy: 0.6071987480438185\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch: 35] | Batch 180 | Loss: 1.9874683843340193: : 180it [01:02,  4.63it/s]\n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss did not improve\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch: 36] | Batch 180 | Loss: 1.963235319028666: : 180it [01:04,  5.48it/s] \n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss did not improve\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch: 37] | Batch 180 | Loss: 1.9392913635697093: : 180it [01:09,  4.63it/s]\n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss improved from 1.0509331226348877 to 1.0128012895584106\n",
      "Validation accuracy: 0.6118935837245696\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch: 38] | Batch 180 | Loss: 1.9166010909610325: : 180it [01:07,  4.03it/s]\n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss did not improve\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-28-532731b4236c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     14\u001b[0m                                          time_steps, stride, True), 1)) as pbar:\n\u001b[1;32m     15\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mbatch_num\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mbatch_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_lens\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpbar\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m             \u001b[0mbatch_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpad_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_lens\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m             \u001b[0mbatch_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/analytics/lib/python3.7/site-packages/tqdm/_tqdm.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    935\u001b[0m \"\"\", fp_write=getattr(self.fp, 'write', sys.stderr.write))\n\u001b[1;32m    936\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 937\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    938\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    939\u001b[0m                 \u001b[0;31m# Update and possibly print the progressbar.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-9-20cf31221793>\u001b[0m in \u001b[0;36mgenerate_batches\u001b[0;34m(data, split, batch_size, time_steps, stride, randomise)\u001b[0m\n\u001b[1;32m     23\u001b[0m             \u001b[0mwindow\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmat\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mj\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mtime_steps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m             \u001b[0mmeans\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwindow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m             \u001b[0mrms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwindow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m             \u001b[0mfeature_vector\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmeans\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/analytics/lib/python3.7/site-packages/numpy/core/_methods.py\u001b[0m in \u001b[0;36m_mean\u001b[0;34m(a, axis, dtype, out, keepdims)\u001b[0m\n\u001b[1;32m     73\u001b[0m             \u001b[0mis_float16_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 75\u001b[0;31m     \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mumr_sum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     76\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmu\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m         ret = um.true_divide(\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "num_epochs = 10000\n",
    "batch_size = 32\n",
    "time_steps = 100\n",
    "stride = 40\n",
    "objective = nn.CrossEntropyLoss()\n",
    "model = HARNet()\n",
    "optimiser = torch.optim.Adam(model.parameters(), weight_decay=0.0001)\n",
    "running_loss = 0\n",
    "running_batch = 0\n",
    "min_valid_loss = float('inf')\n",
    "\n",
    "for epoch in range(1, num_epochs + 1):\n",
    "    with tqdm(enumerate(generate_batches(data, 'train', batch_size,\n",
    "                                         time_steps, stride, True), 1)) as pbar:\n",
    "        model.train()\n",
    "        for batch_num, (batch_data, batch_labels, batch_lens) in pbar:\n",
    "            batch_data = pad_batch(batch_data, batch_lens)\n",
    "            batch_data, batch_labels = torch_batch(batch_data, batch_labels)\n",
    "            optimiser.zero_grad()\n",
    "            preds = model(batch_data, batch_lens)\n",
    "            loss = objective(preds, batch_labels)\n",
    "            loss.backward()\n",
    "            optimiser.step()\n",
    "            running_loss += loss.item()\n",
    "            running_batch += 1\n",
    "            pbar.set_description(f'[Epoch: {epoch}] | Batch {batch_num} | Loss: {running_loss/running_batch}')\n",
    "            \n",
    "    valid_preds, valid_labels = get_preds(model, data, 'valid',\n",
    "                                          64, time_steps, stride)\n",
    "    \n",
    "    valid_loss = objective(valid_preds, valid_labels).item()\n",
    "    \n",
    "    if valid_loss < min_valid_loss:\n",
    "        print(f'Validation loss improved from {min_valid_loss} to {valid_loss}')\n",
    "        acc = get_accuracy(valid_preds, valid_labels, data['label_encoder'])\n",
    "        print(f'Validation accuracy: {acc}')\n",
    "        min_valid_loss = valid_loss\n",
    "        with open('best_cnn_model.pt', 'wb') as f:\n",
    "            torch.save(model.state_dict(), f)\n",
    "    else:\n",
    "        print('Validation loss did not improve')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_state_dict(torch.load('best_cnn_model.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_preds, train_labels = get_preds(model, data, 'train',\n",
    "                                          64, time_steps, stride)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1921447217464447"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_loss = objective(train_preds, train_labels).item()\n",
    "train_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9416985729202924"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc = get_accuracy(train_preds, train_labels, data['label_encoder'])\n",
    "acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_preds, valid_labels = get_preds(model, data, 'valid',\n",
    "                                          64, time_steps, stride)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.27615249156951904"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_loss = objective(valid_preds, valid_labels).item()\n",
    "valid_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9248826291079812"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc = get_accuracy(valid_preds, valid_labels, data['label_encoder'])\n",
    "acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
