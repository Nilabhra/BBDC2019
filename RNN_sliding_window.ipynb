{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "from sklearn.externals import joblib\n",
    "from collections import Counter\n",
    "from scipy import signal\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = joblib.load('data.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = 'bbdc_2019_Bewegungsdaten/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['features', 'labels', 'bounds', 'lens', 'label_encoder'])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def standard_scale(data):\n",
    "    features = data['features']\n",
    "    lens = np.concatenate((data['lens']['train'],data['lens']['valid'],data['lens']['test']))\n",
    "    features = np.concatenate(features, axis=0)\n",
    "    features = StandardScaler().fit_transform(features)\n",
    "    ret = []\n",
    "    l = 0\n",
    "    for t in lens:\n",
    "        ret.append(features[l: l + t])\n",
    "        l += t\n",
    "    features = np.array(ret)\n",
    "    data['features'] = features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_emg(x):\n",
    "    high = 20/(1000/2)\n",
    "    low = 450/(1000/2)\n",
    "    b, a = signal.butter(4, [high, low], btype='bandpass')\n",
    "    emg_filtered = signal.filtfilt(b, a, x, axis=0)\n",
    "    return emg_filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# standard_scale(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_split(data, split):\n",
    "    if split == 'train':\n",
    "        return data['features'][: data['bounds']['train']]\n",
    "    elif split == 'valid':\n",
    "        return data['features'][data['bounds']['train']: data['bounds']['train'] + data['bounds']['valid']]\n",
    "    elif split == 'test':\n",
    "        return data['features'][data['bounds']['train'] + data['bounds']['valid']:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_batch_idx(n, batch_size, randomise=False):\n",
    "    idx = np.arange(0, n)\n",
    "    if randomise:\n",
    "        np.random.shuffle(idx)\n",
    "    for batch_idx in np.arange(0, n, batch_size):\n",
    "        yield idx[batch_idx:batch_idx+batch_size]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_batches(data, split, batch_size,\n",
    "                     time_steps=10, stride=5, randomise=False):\n",
    "    features = get_split(data, split)\n",
    "\n",
    "    try:\n",
    "        labels = data['label_encoder'].transform(data['labels'][split])\n",
    "    except:\n",
    "        labels = np.zeros(features.shape[0])\n",
    "    \n",
    "    lens = data['lens'][split]\n",
    "    new_features = []\n",
    "    new_labels = []\n",
    "    new_lens = []\n",
    "    for i in range(len(lens)):\n",
    "        mat = features[i]\n",
    "        label = labels[i]\n",
    "        l = lens[i]\n",
    "        acc_emg = [0, 1, 2, 3, 5, 6, 7, 9, 10, 11]\n",
    "        mat[:, acc_emg] -= mat[:, acc_emg].mean(axis=0)\n",
    "        mat[:, :4] = filter_emg(mat[:, :4])\n",
    "        extracted_steps = []\n",
    "        for j in range(0, len(mat) - time_steps, stride):\n",
    "            window = mat[j: j + time_steps, :]\n",
    "            means = window[:, 4:].mean(axis=0).reshape(1, -1)\n",
    "            rms = np.sqrt((window[:, :4]**2).mean(axis=0)).reshape(1, -1)\n",
    "            feature_vector = np.concatenate((rms, means), axis=1).reshape(1, -1)\n",
    "            \n",
    "            extracted_steps.append(feature_vector)\n",
    "        extracted_steps = np.concatenate(extracted_steps, axis=0)\n",
    "        new_features.append(extracted_steps)\n",
    "        new_labels.append(label)\n",
    "        new_lens.append(len(extracted_steps))\n",
    "    features = np.array(new_features)\n",
    "    labels = np.array(new_labels)\n",
    "    lens = np.array(new_lens)\n",
    "    \n",
    "    n = len(features)\n",
    "    for batch_idx in generate_batch_idx(n, batch_size, randomise):\n",
    "        batch_data = features[batch_idx]\n",
    "        batch_labels = labels[batch_idx]\n",
    "        batch_lens = lens[batch_idx]\n",
    "#         batch_data = torch.from_numpy(batch_data).float()\n",
    "#         batch_labels = torch.from_numpy(labels[batch_idx]).float()\n",
    "#         lens = torch.from_numpy(lens[batch_idx]).float()\n",
    "        yield batch_data, batch_labels, batch_lens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def sort_batch(batch, targets, lengths):\n",
    "#     \"\"\"\n",
    "#     Sort a minibatch by the length of the sequences with the longest sequences first\n",
    "#     return the sorted batch targes and sequence lengths.\n",
    "#     This way the output can be used by pack_padded_sequences(...)\n",
    "#     \"\"\"\n",
    "#     perm_idx = np.argsort(lengths)[::-1]\n",
    "#     seq_lengths = lengths[perm_idx]\n",
    "#     seq_tensor = batch[perm_idx]\n",
    "#     target_tensor = targets[perm_idx]\n",
    "#     return seq_tensor, target_tensor, seq_lengths\n",
    "\n",
    "def pad_batch(batch, lens):\n",
    "    max_len = max(lens)\n",
    "    batch_size = batch.shape[0]\n",
    "    num_feature = batch[0].shape[1]\n",
    "    padded_seqs = np.zeros((batch_size, max_len, num_feature))\n",
    "    \n",
    "    for i, l in enumerate(lens):\n",
    "        padded_seqs[i, :l, :] = batch[i][:l]\n",
    "\n",
    "    return padded_seqs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def torch_batch(batch, targets):\n",
    "    return torch.from_numpy(batch).float(), torch.from_numpy(targets).long()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_preds(model, data, split, batch_size, time_steps, stride):\n",
    "    model.eval()\n",
    "    preds = []\n",
    "    labels = []\n",
    "    with torch.no_grad():\n",
    "        for b_data, b_labels, b_lens in generate_batches(data, split, batch_size, \n",
    "                                                         time_steps, stride, False):\n",
    "            b_data = pad_batch(b_data, b_lens)\n",
    "            b_data, b_labels = torch_batch(b_data, b_labels)\n",
    "            preds.append(model(b_data, b_lens))\n",
    "            labels.append(b_labels)\n",
    "        preds = torch.cat(preds, dim=0)\n",
    "        labels = torch.cat(labels, dim=0)\n",
    "    return preds, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_accuracy(preds, labels, le):\n",
    "    preds = preds.max(dim=1)[1].numpy()\n",
    "    preds = [le.classes_[i] for i in preds]\n",
    "    labels = labels.numpy()\n",
    "    labels = [le.classes_[i] for i in labels]\n",
    "    return accuracy_score(labels, preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HARNet(nn.Module):\n",
    "    def __init__(self, ):\n",
    "        super().__init__()\n",
    "        self.rnn1 = nn.GRU(19, 64, num_layers=1, batch_first=True)\n",
    "#         self.rnn2 = nn.RNN(64, 64)\n",
    "        self.lin1 = nn.Linear(64*2, 128, bias=True)\n",
    "        self.lin2 = nn.Linear(128, 64, bias=True)\n",
    "        self.lin3 = nn.Linear(64, 22, bias=True)\n",
    "        self.dropout = nn.Dropout(0.2)\n",
    "    def forward(self, data, lens):\n",
    "        x, _ = self.rnn1(data)\n",
    "        attn = torch.bmm(x, x.transpose(2, 1))\n",
    "        lens = torch.from_numpy(lens).view(-1, 1, 1)\n",
    "        mask = torch.arange(x.size(1)).repeat(x.size(0), x.size(1), 1)\n",
    "        mask = mask > lens\n",
    "        attn.masked_fill_(mask, -np.inf)\n",
    "        attn = F.softmax(attn, dim=2)\n",
    "        x = torch.bmm(attn, x)\n",
    "        x_max = x.max(dim=1)[0]\n",
    "        x_avg = x.mean(dim=1)\n",
    "#         x_max = torch.cat([seq[0:l,:].max(dim=0)[0].view(1, -1) for l, seq in zip(lens, x)], dim=0)\n",
    "#         x_min = torch.cat([seq[0:l,:].min(dim=0)[0].view(1, -1) for l, seq in zip(lens, x)], dim=0)\n",
    "#         x_avg = torch.cat([seq[0:l,:].mean(dim=0).view(1, -1) for l, seq in zip(lens, x)], dim=0)\n",
    "        x = torch.cat((x_avg, x_max), dim=1)\n",
    "        x = self.dropout(x)\n",
    "        x = self.lin1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.lin2(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.lin3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch: 1] | Batch 180 | Loss: 2.7066100425190394: : 180it [00:42,  4.20it/s]\n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss improved from inf to 2.320127487182617\n",
      "Validation accuracy: 0.23317683881064163\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch: 2] | Batch 180 | Loss: 2.445647530754407: : 180it [00:42,  4.20it/s] \n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss improved from 2.320127487182617 to 1.8497079610824585\n",
      "Validation accuracy: 0.3114241001564945\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch: 3] | Batch 180 | Loss: 2.3067950306115326: : 180it [00:43,  4.14it/s]\n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss did not improve\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch: 4] | Batch 180 | Loss: 2.226175958249304: : 180it [00:39,  4.52it/s] \n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss improved from 1.8497079610824585 to 1.7824411392211914\n",
      "Validation accuracy: 0.3208137715179969\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch: 5] | Batch 180 | Loss: 2.1601816329691146: : 180it [00:40,  4.45it/s]\n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss improved from 1.7824411392211914 to 1.7647250890731812\n",
      "Validation accuracy: 0.28169014084507044\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 10000\n",
    "batch_size = 32\n",
    "time_steps = 100\n",
    "stride = 50\n",
    "objective = nn.CrossEntropyLoss()\n",
    "model = HARNet()\n",
    "optimiser = torch.optim.Adam(model.parameters(), weight_decay=0.000)\n",
    "running_loss = 0\n",
    "running_batch = 0\n",
    "min_valid_loss = float('inf')\n",
    "\n",
    "for epoch in range(1, num_epochs + 1):\n",
    "    with tqdm(enumerate(generate_batches(data, 'train', batch_size,\n",
    "                                         time_steps, stride, True), 1)) as pbar:\n",
    "        model.train()\n",
    "        for batch_num, (batch_data, batch_labels, batch_lens) in pbar:\n",
    "            batch_data = pad_batch(batch_data, batch_lens)\n",
    "            batch_data, batch_labels = torch_batch(batch_data, batch_labels)\n",
    "            optimiser.zero_grad()\n",
    "            preds = model(batch_data, batch_lens)\n",
    "            loss = objective(preds, batch_labels)\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), 4, norm_type=2)\n",
    "            optimiser.step()\n",
    "            running_loss += loss.item()\n",
    "            running_batch += 1\n",
    "            pbar.set_description(f'[Epoch: {epoch}] | Batch {batch_num} | Loss: {running_loss/running_batch}')\n",
    "            \n",
    "    valid_preds, valid_labels = get_preds(model, data, 'valid',\n",
    "                                          64, time_steps, stride)\n",
    "    \n",
    "    valid_loss = objective(valid_preds, valid_labels).item()\n",
    "    \n",
    "    if valid_loss < min_valid_loss:\n",
    "        print(f'Validation loss improved from {min_valid_loss} to {valid_loss}')\n",
    "        acc = get_accuracy(valid_preds, valid_labels, data['label_encoder'])\n",
    "        print(f'Validation accuracy: {acc}')\n",
    "        min_valid_loss = valid_loss\n",
    "        with open('best_rnn_model.pt', 'wb') as f:\n",
    "            torch.save(model.state_dict(), f)\n",
    "    else:\n",
    "        print('Validation loss did not improve')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_state_dict(torch.load('best_rnn_model.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nilavro/miniconda3/envs/analytics/lib/python3.7/site-packages/scipy/signal/_arraytools.py:45: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  b = a[a_slice]\n"
     ]
    }
   ],
   "source": [
    "train_preds, train_labels = get_preds(model, data, 'train',\n",
    "                                          64, time_steps, stride)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.5043046474456787"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_loss = objective(train_preds, train_labels).item()\n",
    "train_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.43340060544904135"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc = get_accuracy(train_preds, train_labels, data['label_encoder'])\n",
    "acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_preds, valid_labels = get_preds(model, data, 'valid',\n",
    "                                          64, time_steps, stride)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.6424287557601929"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_loss = objective(valid_preds, valid_labels).item()\n",
    "valid_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3895216400911162"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc = get_accuracy(valid_preds, valid_labels, data['label_encoder'])\n",
    "acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1, 1, 0, 0, 0],\n",
       "         [1, 1, 1, 1, 1],\n",
       "         [1, 1, 1, 1, 0],\n",
       "         [1, 1, 1, 0, 0]]], dtype=torch.uint8)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(torch.arange(5).repeat(4,1) < torch.LongTensor([2, 5, 4, 3]).view(-1, 1)).repeat(1, 1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1, 1, 0, 0, 0],\n",
       "         [1, 1, 0, 0, 0],\n",
       "         [1, 1, 0, 0, 0],\n",
       "         [1, 1, 0, 0, 0],\n",
       "         [1, 1, 0, 0, 0]],\n",
       "\n",
       "        [[1, 1, 1, 1, 1],\n",
       "         [1, 1, 1, 1, 1],\n",
       "         [1, 1, 1, 1, 1],\n",
       "         [1, 1, 1, 1, 1],\n",
       "         [1, 1, 1, 1, 1]],\n",
       "\n",
       "        [[1, 1, 1, 1, 0],\n",
       "         [1, 1, 1, 1, 0],\n",
       "         [1, 1, 1, 1, 0],\n",
       "         [1, 1, 1, 1, 0],\n",
       "         [1, 1, 1, 1, 0]],\n",
       "\n",
       "        [[1, 1, 1, 0, 0],\n",
       "         [1, 1, 1, 0, 0],\n",
       "         [1, 1, 1, 0, 0],\n",
       "         [1, 1, 1, 0, 0],\n",
       "         [1, 1, 1, 0, 0]]], dtype=torch.uint8)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.arange(5).repeat(4,5,1) < torch.LongTensor([2, 5, 4, 3]).view(-1, 1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
